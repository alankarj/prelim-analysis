{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path:  /Users/alankar/Documents/cmu/code/prelim-analysis/data/davos/user_cs_profile.csv\n",
      "Data matrix size:  (64, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alankar/miniconda3/envs/prelim-analysis-research/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages:  0.24619138509921284\n",
      "Standard Deviation:  0.0072093096757323925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.cluster as skclust\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "\n",
    "data_path = os.path.abspath('../') + '/data/davos/' # Change this to path to your data folder.\n",
    "file_name = 'user_cs_profile' # Name of the CSV file (input).\n",
    "csv_ext = '.csv'\n",
    "\n",
    "k = 2\n",
    "num_seeds = 5\n",
    "\n",
    "file_path = os.path.join(data_path, file_name + csv_ext)\n",
    "print(\"File path: \", file_path)\n",
    "\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "X = data.as_matrix()\n",
    "X = preprocessing.scale(X, axis=0)\n",
    "print(\"Data matrix size: \", X.shape)\n",
    "\n",
    "sil_scores = np.zeros(num_seeds)\n",
    "for seed in range(num_seeds):\n",
    "    # Get k-means clusters\n",
    "    random_state = np.random.randint(1000)\n",
    "    est = skclust.KMeans(n_clusters = k, random_state=random_state)\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "    \n",
    "    # Get Silhouette scores for evaluation (between 0 and 1; the higher the better)\n",
    "    sil_scores[seed] = metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "    \n",
    "    # Write labels to a csv file\n",
    "    data['Cluster'] = labels\n",
    "    output_file_name = file_name + '_clusters' + '_' + str(random_state) # Output file name.\n",
    "    data.to_csv(data_path + output_file_name + csv_ext)\n",
    "\n",
    "# Average and standard deviation of Silhouette score (over num_seeds runs)\n",
    "print(\"Averages: \", np.average(sil_scores))\n",
    "print(\"Standard Deviation: \", np.std(sil_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'final_clusters.csv'\n",
    "cluster_file_name = 'clusters_full.pkl'\n",
    "\n",
    "tid_col_name = 'Transcript ID'\n",
    "cluster_col_name = 'Final Cluster'\n",
    "\n",
    "df = pd.read_csv(data_path + output_file_name, index_col=None)\n",
    "cluster_map = dict(zip(df[tid_col_name], df[cluster_col_name]))\n",
    "\n",
    "with open(data_path + cluster_file_name, 'wb') as f:\n",
    "    pickle.dump(cluster_map, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
