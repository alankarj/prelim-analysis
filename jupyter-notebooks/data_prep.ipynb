{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"0\": {\n",
      "    \"user_cs_outp\": null,\n",
      "    \"rapp_outp\": null,\n",
      "    \"user_cs_inp_t-1\": null,\n",
      "    \"user_cs_inp_t-2\": null,\n",
      "    \"agent_cs_inp_t-0\": null,\n",
      "    \"agent_cs_inp_t-1\": null,\n",
      "    \"agent_intention_inp_t-0\": null,\n",
      "    \"agent_intention_inp_t-1\": null,\n",
      "    \"rapp_inp_t-1\": null,\n",
      "    \"rapp_inp_t-2\": null\n",
      "  },\n",
      "  \"1\": {\n",
      "    \"user_cs_outp\": null,\n",
      "    \"rapp_outp\": null,\n",
      "    \"user_cs_inp_t-1\": null,\n",
      "    \"user_cs_inp_t-2\": null,\n",
      "    \"agent_cs_inp_t-0\": null,\n",
      "    \"agent_cs_inp_t-1\": null,\n",
      "    \"agent_intention_inp_t-0\": null,\n",
      "    \"agent_intention_inp_t-1\": null,\n",
      "    \"rapp_inp_t-1\": null,\n",
      "    \"rapp_inp_t-2\": null\n",
      "  },\n",
      "  \"all\": {\n",
      "    \"user_cs_outp\": null,\n",
      "    \"rapp_outp\": null,\n",
      "    \"user_cs_inp_t-1\": null,\n",
      "    \"user_cs_inp_t-2\": null,\n",
      "    \"agent_cs_inp_t-0\": null,\n",
      "    \"agent_cs_inp_t-1\": null,\n",
      "    \"agent_intention_inp_t-0\": null,\n",
      "    \"agent_intention_inp_t-1\": null,\n",
      "    \"rapp_inp_t-1\": null,\n",
      "    \"rapp_inp_t-2\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "parent_path = os.path.abspath('../')\n",
    "data_path = parent_path + '/data/davos/'\n",
    "\n",
    "participants = ['agent', 'user']\n",
    "suffix_str = ['_timestamps.pkl', '_cs.pkl', '_intention.pkl']\n",
    "\n",
    "participant_paths = []\n",
    "for p in participants:\n",
    "    participant_paths.append(data_path + p + '_cs/')\n",
    "participant_paths[1] += 'pickle_files/'\n",
    "    \n",
    "cluster_file = data_path + 'clusters_full.pkl'\n",
    "id_to_f_file = data_path + 'id_to_f_full.pkl'\n",
    "last_slice_fname = data_path + 'last_slice_length_full.txt'\n",
    "tot_length_fname = data_path + 'length_full.txt'\n",
    "train_data_fname = data_path + 'train_data_full.pkl'\n",
    "\n",
    "window = 2 # How back do we go in the past\n",
    "input_variables = ['user_cs_inp', 'agent_cs_inp', 'agent_intention_inp', 'rapp_inp']\n",
    "output_variables = ['user_cs_outp', 'rapp_outp']\n",
    "all_str = 'all'\n",
    "\n",
    "clusters = pickle.load(open(cluster_file, 'rb'))\n",
    "id_to_f = pickle.load(open(id_to_f_file, 'rb'))\n",
    "\n",
    "all_sessions = id_to_f.keys()\n",
    "\n",
    "unique_clusters = list(set(list(clusters.values())))\n",
    "unique_clusters.append(all_str)\n",
    "\n",
    "data = {}\n",
    "for uc in unique_clusters:\n",
    "    data[uc] = {}\n",
    "    for ov in output_variables:\n",
    "        data[uc][ov] = None\n",
    "    for i, iv in enumerate(input_variables):\n",
    "        for w in range(window):\n",
    "            if iv in ['agent_cs_inp', 'agent_intention_inp']:\n",
    "                w -= 1\n",
    "            data[uc][iv + '_t-' + str(w+1)] = None\n",
    "\n",
    "print(json.dumps(data, indent=2))\n",
    "\n",
    "\n",
    "def get_map(fname):\n",
    "    map_dict = {}\n",
    "    with open(fname, 'r') as f:\n",
    "        rows = f.readlines()\n",
    "        for r in rows:\n",
    "            r = r.split(\" \")\n",
    "            key = r[0].strip()\n",
    "            val = int(r[1].strip())\n",
    "            map_dict[key] = val\n",
    "    return map_dict\n",
    "\n",
    "last_slice_length = get_map(last_slice_fname)\n",
    "tot_length = get_map(tot_length_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def fit(self, cs_types):\n",
    "        onehotvec = np.zeros(len(self.data))\n",
    "        for c in cs_types:\n",
    "            if c == 'QE':\n",
    "                c = 'QESD'\n",
    "            onehotvec[self.data.index(c)] = 1\n",
    "        return onehotvec\n",
    "\n",
    "cs_types = {}\n",
    "intention_types = {}\n",
    "cs_types['agent'] = ['ASN', 'ACK', 'SD', 'QESD', 'PR', 'HE', 'VSN', 'NONE']\n",
    "cs_types['user'] = ['SD', 'QESD', 'PR', 'HE', 'VSN', 'NONE']\n",
    "intention_types['agent'] = ['ack()', 'request(met_before)', 'take_selfie()', 'give_feedback()', 'tired()', 'request(selfie)', 'request(send_msg_tlink)', 'request(another_reco)', 'greeting()', 'request(first_time)', 'no_worries()', 'do()', 'request(interest)', 'thank()', 'bye()', 'request(goal)', 'send_msg()', 'request(feedback)', 'introduce()', 'glad()', 'sorry()', 'request(anything_else)', 'request(primary_goal)', 'other()', 'inform(info)', 'you()']\n",
    "\n",
    "enc = {}\n",
    "for p in participants:\n",
    "    enc[p] = CategoricalEncoder(cs_types[p])\n",
    "enc['agent_intention'] = CategoricalEncoder(intention_types['agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_in_time(mat, n):\n",
    "    \"\"\"Shifts the given 2-d matrix mat by n (rows), appending n zero arrays to its top\"\"\"\n",
    "    assert mat.ndim == 2\n",
    "    if n == 0:\n",
    "        return mat\n",
    "    mat = mat[:-n, :]\n",
    "    r, c = mat.shape\n",
    "    padding = np.zeros((n, c))\n",
    "    return np.concatenate((padding, mat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing session: 514928...Processing agent...rapp_inp_t-1\n",
      "rapp_inp_t-2\n",
      "agent_intention_inp_t-0\n",
      "agent_intention_inp_t-1\n",
      "agent_cs_inp_t-0\n",
      "agent_cs_inp_t-1\n",
      "Done.Processing user...user_cs_inp_t-1\n",
      "user_cs_inp_t-2\n",
      "Done.Done.\n",
      "Processing session: 515151...Processing agent...rapp_inp_t-1\n",
      "rapp_inp_t-2\n",
      "agent_intention_inp_t-0\n",
      "agent_intention_inp_t-1\n",
      "agent_cs_inp_t-0\n",
      "agent_cs_inp_t-1\n",
      "Done.Processing user...user_cs_inp_t-1\n",
      "user_cs_inp_t-2\n",
      "Done.Done.\n",
      "Processing session: 515233...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 515289...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 515762...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 515843...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 516135...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 516417...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 516517...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1001335...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1001444...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1001636...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1001877...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1001918...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002013...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002242...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002281...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002422...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002648...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1002655...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1003016...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 1003158...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2001299...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2001521...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2001541...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2002040...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2004828...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2005036...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2005133...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2008165...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 2016938...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 509907...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 509921...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 509969...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 509997...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510196...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510275...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510401...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510410...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510422...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510457...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510500...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510688...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510734...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510849...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510881...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510910...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510918...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 510999...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 511250...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 511447...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 511512...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 511665...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 511862...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513033...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513058...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513324...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513762...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513935...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513969...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 514007...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 514819...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 512508...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 513210...Processing agent...Done.Processing user...Done.Done.\n",
      "Processing session: 514232...Processing agent...Done.Processing user...Done.Done.\n",
      "0\n",
      "user_cs_outp\n",
      "(960, 6)\n",
      "rapp_outp\n",
      "(960, 1)\n",
      "user_cs_inp_t-1\n",
      "(960, 6)\n",
      "user_cs_inp_t-2\n",
      "(960, 6)\n",
      "agent_cs_inp_t-0\n",
      "(960, 8)\n",
      "agent_cs_inp_t-1\n",
      "(960, 8)\n",
      "agent_intention_inp_t-0\n",
      "(960, 26)\n",
      "agent_intention_inp_t-1\n",
      "(960, 26)\n",
      "rapp_inp_t-1\n",
      "(960, 1)\n",
      "rapp_inp_t-2\n",
      "(960, 1)\n",
      "1\n",
      "user_cs_outp\n",
      "(545, 6)\n",
      "rapp_outp\n",
      "(545, 1)\n",
      "user_cs_inp_t-1\n",
      "(545, 6)\n",
      "user_cs_inp_t-2\n",
      "(545, 6)\n",
      "agent_cs_inp_t-0\n",
      "(545, 8)\n",
      "agent_cs_inp_t-1\n",
      "(545, 8)\n",
      "agent_intention_inp_t-0\n",
      "(545, 26)\n",
      "agent_intention_inp_t-1\n",
      "(545, 26)\n",
      "rapp_inp_t-1\n",
      "(545, 1)\n",
      "rapp_inp_t-2\n",
      "(545, 1)\n",
      "all\n",
      "user_cs_outp\n",
      "(1505, 6)\n",
      "rapp_outp\n",
      "(1505, 1)\n",
      "user_cs_inp_t-1\n",
      "(1505, 6)\n",
      "user_cs_inp_t-2\n",
      "(1505, 6)\n",
      "agent_cs_inp_t-0\n",
      "(1505, 8)\n",
      "agent_cs_inp_t-1\n",
      "(1505, 8)\n",
      "agent_intention_inp_t-0\n",
      "(1505, 26)\n",
      "agent_intention_inp_t-1\n",
      "(1505, 26)\n",
      "rapp_inp_t-1\n",
      "(1505, 1)\n",
      "rapp_inp_t-2\n",
      "(1505, 1)\n"
     ]
    }
   ],
   "source": [
    "outp_base_str = \"_cs_outp\"\n",
    "inp_base_str = \"_cs_inp_t-\"\n",
    "rapp_outp_str = \"rapp_outp\"\n",
    "rapp_inp_str = \"rapp_inp_t-\"\n",
    "agent_intention_inp_str = \"agent_intention_inp_t-\"\n",
    "rapp_lower_bound = 2 # rapport lower bound\n",
    "rapp_upper_bound = 6 # rapport upper bound\n",
    "task_intention_binary = None\n",
    "\n",
    "flag = {}\n",
    "for clust in clusters.values():\n",
    "    flag[clust] = {}\n",
    "    for p in participants:\n",
    "        flag[clust][p] = False\n",
    "\n",
    "def update_data(window, data, clust, base_str, array, create_new=False, decr_window=False):\n",
    "    for w in range(window):\n",
    "        if decr_window:\n",
    "            w -= 1\n",
    "        if create_new:\n",
    "            print(base_str + str(w+1))\n",
    "            data[clust][base_str + str(w+1)] = shift_in_time(array, w+1)\n",
    "        else:\n",
    "            data[clust][base_str + str(w+1)] = np.concatenate((data[clust][base_str + str(w+1)], shift_in_time(array, w+1)), axis=0)\n",
    "    return data\n",
    "\n",
    "first_time = {}\n",
    "num_cs = {}\n",
    "\n",
    "for i, sid in enumerate(all_sessions):\n",
    "    print(\"Processing session: %s...\" %(sid), end='')\n",
    "    clust = clusters[int(sid)]\n",
    "    \n",
    "    for q in participants:\n",
    "        # -1 means these have not been updated yet.\n",
    "        first_time[q] = -1\n",
    "        num_cs[q] = -1\n",
    "    \n",
    "    for j, p in enumerate(participants):\n",
    "        print(\"Processing %s...\" %(p), end='')\n",
    "        tstmp = pickle.load(open(participant_paths[j] + sid + '_' + p + suffix_str[0], 'rb'))\n",
    "        t = list(tstmp.values())\n",
    "        orig_len = len(t)\n",
    "        # Drop time stamps for last slice\n",
    "        t = [i for i in t if tot_length[sid] - i > last_slice_length[sid]]\n",
    "        new_len = len(t)\n",
    "        cs = pickle.load(open(participant_paths[j] + sid + '_' + p + suffix_str[1], 'rb'))\n",
    "        if p == participants[0]:\n",
    "            task_intention = pickle.load(open(participant_paths[j] + sid + '_' + p + suffix_str[2], 'rb'))\n",
    "        diff = orig_len-new_len\n",
    "        \n",
    "        # Drop CSs for last slice\n",
    "        if diff > 0:\n",
    "            cs = list(cs.values())[:-diff]\n",
    "            if p == 'agent':\n",
    "                task_intention = list(task_intention.values())[:-diff]\n",
    "        else:\n",
    "            cs = list(cs.values())\n",
    "            if p == participants[0]:\n",
    "                task_intention = list(task_intention.values())\n",
    "        \n",
    "        if p == participants[0]:\n",
    "            # This is true only for agent.\n",
    "            assert len(t) == len(cs)\n",
    "            assert len(t) == len(task_intention)\n",
    "        \n",
    "        first_time[p] = t[0]\n",
    "        num_cs[p] = len(cs)\n",
    "        num_intention = len(task_intention)\n",
    "        \n",
    "        time_updated = True\n",
    "        for q in participants:\n",
    "            if first_time[q] == -1:\n",
    "                time_updated = False  \n",
    "        \n",
    "        if time_updated:\n",
    "            if first_time[participants[0]] - first_time[participants[1]] > 0:\n",
    "                # Drop the first user CS if the user spoke first!\n",
    "                cs.pop(0)\n",
    "            num_cs[p] = len(cs)\n",
    "            assert num_cs[participants[0]] - num_cs[participants[1]] <= 1\n",
    "            if num_cs[participants[0]] - num_cs[participants[1]] == 1:\n",
    "                cs.append(['NONE'])\n",
    "            num_cs[p] = len(cs)\n",
    "#             print(num_cs[participants[0]])\n",
    "#             print(num_cs[participants[1]])\n",
    "        \n",
    "        # Binary representation of the conversational strategies used in the entire interaction by the \n",
    "        # given participant (user or agent)\n",
    "        cs_binary = np.array([enc[p].fit(c) for c in cs])\n",
    "        rapp = id_to_f[sid](np.array(t))[:, np.newaxis]\n",
    "        if p == participants[0]:\n",
    "            task_intention_binary = np.array([enc[p + '_intention'].fit(ti) for ti in task_intention])\n",
    "#             print(task_intention_binary)\n",
    "        x = rapp[rapp < rapp_lower_bound].tolist()\n",
    "        y = rapp[rapp > rapp_upper_bound].tolist()\n",
    "        correct_indices = np.where((rapp >= rapp_lower_bound) & (rapp <= rapp_upper_bound))[0]\n",
    "        \n",
    "        # Nearest neighbour interpolation for out of bound rapport values\n",
    "        if x != []:\n",
    "            problem_indices = np.where(rapp < rapp_lower_bound)[0]\n",
    "            nearest_indices = np.argsort(abs(problem_indices[:, np.newaxis]-correct_indices[np.newaxis, :]), axis=1)[:, 0]\n",
    "            rapp[problem_indices] = rapp[correct_indices[nearest_indices]]\n",
    "        if y != []:\n",
    "            problem_indices = np.where(rapp > rapp_upper_bound)[0]\n",
    "            nearest_indices = np.argsort(abs(problem_indices[:, np.newaxis]-correct_indices[np.newaxis, :]), axis=1)[:, 0]\n",
    "            rapp[problem_indices] = rapp[correct_indices[nearest_indices]]\n",
    "\n",
    "        base_str = [p + inp_base_str, rapp_inp_str, agent_intention_inp_str]\n",
    "        to_be_added = [cs_binary, rapp, task_intention_binary]\n",
    "        if not flag[clust][p]:\n",
    "            if p == 'agent':\n",
    "                # Create rapp_outp.\n",
    "                data[clust][rapp_outp_str] = rapp\n",
    "                data = update_data(window, data, clust, base_str[1], to_be_added[1], create_new=True, decr_window=False)\n",
    "                dw = True\n",
    "                data = update_data(window, data, clust, base_str[2], to_be_added[2], create_new=True, decr_window=dw)\n",
    "            if p == 'user':\n",
    "                # U_0 should be as it is.\n",
    "                data[clust][p + outp_base_str] = cs_binary\n",
    "                dw = False\n",
    "            data = update_data(window, data, clust, base_str[0], to_be_added[0], create_new=True, decr_window=dw)\n",
    "            flag[clust][p] = True\n",
    "        else:\n",
    "            if p == 'agent':\n",
    "                # Create rapp_outp.\n",
    "                data[clust][rapp_outp_str] = np.concatenate((data[clust][rapp_outp_str], rapp), axis=0)\n",
    "                data = update_data(window, data, clust, base_str[1], to_be_added[1], create_new=False, decr_window=False)\n",
    "                dw = True\n",
    "                data = update_data(window, data, clust, base_str[2], to_be_added[2], create_new=False, decr_window=dw)\n",
    "            if p == 'user':\n",
    "                data[clust][p + outp_base_str] = np.concatenate((data[clust][p + outp_base_str], cs_binary), axis=0)\n",
    "                dw = False\n",
    "            data = update_data(window, data, clust, base_str[0], to_be_added[0], create_new=False, decr_window=dw)\n",
    "        print(\"Done.\", end='')\n",
    "    print(\"Done.\")\n",
    "        \n",
    "for k, v in data[all_str].items():\n",
    "    data[all_str][k] = np.vstack([data[c][k] for c in unique_clusters[:-1]])\n",
    "\n",
    "for keys, vals in data.items():\n",
    "    print(keys)\n",
    "    for k, v in vals.items():\n",
    "        print(k)\n",
    "        print(np.shape(v))\n",
    "\n",
    "with open(train_data_fname, 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
